{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VicunaAGI Project\n",
    "- [Oobabooga Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)\n",
    "- [Vicuna 13B Model](https://github.com/lm-sys/FastChat/#vicuna-weights)\n",
    "- Modified [BabyAGI](https://github.com/yoheinakajima/babyagi)\n",
    "\n",
    "# Setup Instructions\n",
    "\n",
    "This notebook is intended for use in Ubuntu Linux and assumes you have a GPU capable of running this model with the appropriate drivers installed.\n",
    "\n",
    "## Install Initial Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r \"requirements.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "curl -sL \"https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\" > \"Miniconda3.sh\"\n",
    "sudo bash Miniconda3.sh\n",
    "sudo apt install build-essential\n",
    "conda create -n textgen python=3.10.9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Oobabooga Text Generation Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "git clone https://github.com/oobabooga/text-generation-webui\n",
    "cd text-generation-webui\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Vicuna 13B Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python3 download-model.py eachadea/vicuna-13b-1.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Oobabooga Text Generation Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "conda activate textgen\n",
    "python3 server.py --chat --model eachadea_vicuna-13b-1.1 --listen --no-stream"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access at http://localhost:7860/?__theme=dark once running."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set The AI Objectives and Server location\n",
    "Leave the ``OOBA_SERVER`` as ``localhost`` if you're running the Oobabooga Text Generation Web UI on your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOBA_SERVER = \"localhost\"\n",
    "OBJECTIVE = \"Solve world hunger\"\n",
    "INITIAL_TASK = \"Develop a task list.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start VicunaAGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from collections import deque\n",
    "from typing import Dict, List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "OOBA_SERVER = \"localhost\" if OOBA_SERVER is None else OOBA_SERVER\n",
    "\n",
    "def generate_text(prompt):\n",
    "    params = {\n",
    "        'prompt': prompt,\n",
    "        'max_new_tokens': 200,\n",
    "        'temperature': 0.5,\n",
    "        'top_p': 0.9,\n",
    "        'typical_p': 1,\n",
    "        'n': 1,\n",
    "        'stop': None,\n",
    "        'do_sample': True,\n",
    "        'return_prompt': False,\n",
    "        'return_metadata': False,\n",
    "        'typical_p': 0.95,\n",
    "        'repetition_penalty': 1.05,\n",
    "        'encoder_repetition_penalty': 1.0,\n",
    "        'top_k': 0,\n",
    "        'min_length': 0,\n",
    "        'no_repeat_ngram_size': 2,\n",
    "        'num_beams': 1,\n",
    "        'penalty_alpha': 0,\n",
    "        'length_penalty': 1.0,\n",
    "        'early_stopping': False,\n",
    "        'pad_token_id': None,  # Padding token ID, if required\n",
    "        'eos_token_id': None,  # End-of-sentence token ID, if required\n",
    "        'use_cache': True,     # Whether to use caching\n",
    "        'num_return_sequences': 1,  # Number of sequences to return for each input\n",
    "        'bad_words_ids': None,  # List of token IDs that should not appear in the generated text\n",
    "        'seed': -1,\n",
    "    }\n",
    "    response = requests.post(f\"http://{OOBA_SERVER}:7860/run/textgen\", json=params).json()\n",
    "    reply = response[\"data\"][0]\n",
    "    return reply\n",
    "\n",
    "# Print OBJECTIVE\n",
    "print(\"\\033[96m\\033[1m\" + \"\\n*****OBJECTIVE*****\\n\" + \"\\033[0m\\033[0m\")\n",
    "print(OBJECTIVE)\n",
    "\n",
    "# Create FAISS index\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "index = FAISS.from_texts([\"_\"], embeddings_model, metadatas=[{\"task\":INITIAL_TASK}])\n",
    "\n",
    "# Task list\n",
    "task_list = deque([])\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "\n",
    "def add_task(task: Dict):\n",
    "    task_list.append(task)\n",
    "\n",
    "def task_creation_agent(objective: str, result: Dict, task_description: str, task_list: List[str]):\n",
    "    prompt = (\n",
    "        f\"You are an task creation AI that uses the result of an execution agent to create new tasks with the following objective: {objective}, \"\n",
    "        f\"The last completed task has the result: {result}. This result was based on this task description: {task_description}. \"\n",
    "        f\"These are incomplete tasks: {', '.join(task_list)}. \"\n",
    "        f\"Based on the result, create new tasks to be completed by the AI system that do not overlap with incomplete tasks. Return the tasks as an array.\"\n",
    "    )\n",
    "    new_tasks = generate_text(prompt).strip().split(\"\\n\")\n",
    "    return [{\"task_name\": task_name} for task_name in new_tasks]\n",
    "\n",
    "def prioritization_agent(this_task_id: int):\n",
    "    global task_list\n",
    "    task_names = [t[\"task_name\"] for t in task_list]\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    prompt = (\n",
    "        f\"\"\"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing the following tasks: {task_names}. \"\"\"\n",
    "        f\"\"\"Consider the ultimate objective of your team:{OBJECTIVE}. Do not remove any tasks. Return the result as a numbered list, like:\n",
    "    #. First task\n",
    "    #. Second task\n",
    "    Start the task list with number {next_task_id}.\"\"\"\n",
    "    )\n",
    "    new_tasks = generate_text(prompt).strip().split(\"\\n\")\n",
    "    task_list = deque()\n",
    "    for task_string in new_tasks:\n",
    "        task_parts = task_string.strip().split(\".\", 1)\n",
    "        if len(task_parts) == 2:\n",
    "            task_id = task_parts[0].strip()\n",
    "            task_name = task_parts[1].strip()\n",
    "            task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
    "\n",
    "def execution_agent(objective: str, task: str) -> str:\n",
    "    context = context_agent(query=objective, n=5)\n",
    "    prompt = (\n",
    "        f\"You are an AI who performs one task based on the following objective: {objective}.\\n\"\n",
    "        f\"Take into account these previously completed tasks: {context}\\n\"\n",
    "        f\"Your task: {task}\\nResponse:\"\n",
    "    )\n",
    "    return generate_text(prompt).strip()\n",
    "\n",
    "def context_agent(query: str, index: str, n: int):\n",
    "    results = index.similarity_search_with_score(query, k=n)\n",
    "    sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    return [item[0].metadata[\"task\"] for item in sorted_results]\n",
    "\n",
    "# Add the first task\n",
    "first_task = {\"task_id\": 1, \"task_name\": INITIAL_TASK}\n",
    "\n",
    "add_task(first_task)\n",
    "# Main loop\n",
    "task_id_counter = 1\n",
    "while True:\n",
    "    if task_list:\n",
    "        # Print the task list\n",
    "        print(\n",
    "            \"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "        )\n",
    "        for t in task_list:\n",
    "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
    "\n",
    "        # Step 1: Pull the first task\n",
    "        task = task_list.popleft()\n",
    "        print(\n",
    "            \"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "        )\n",
    "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
    "\n",
    "        # Send to execution function to complete the task based on the context\n",
    "        result = execution_agent(OBJECTIVE, task[\"task_name\"])\n",
    "        this_task_id = int(task[\"task_id\"])\n",
    "        print(\n",
    "            \"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\"\n",
    "        )\n",
    "        print(result)\n",
    "\n",
    "        # Step 2: Enrich result and store in index\n",
    "        enriched_result = {\"data\": result}\n",
    "        result_id = f'result_{task[\"task_id\"]}'\n",
    "        index.add_texts([result], metadatas=[{\"task\":task[\"task_name\"]}])\n",
    "\n",
    "    # Step 3: Create new tasks and reprioritize task list\n",
    "    new_tasks = task_creation_agent(OBJECTIVE, enriched_result, task[\"task_name\"], [t[\"task_name\"] for t in task_list])\n",
    "\n",
    "    for new_task in new_tasks:\n",
    "        task_id_counter += 1\n",
    "        new_task.update({\"task_id\": task_id_counter})\n",
    "        add_task(new_task)\n",
    "    prioritization_agent(this_task_id)\n",
    "\n",
    "    time.sleep(1)  # Sleep before checking the task list again\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
